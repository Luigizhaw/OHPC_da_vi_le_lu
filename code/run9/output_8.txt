Initial loss: 7026.473333949661
Iteration 1000: Loss = 3085.2191726368815
Iteration 2000: Loss = 2582.1568055717034
Iteration 3000: Loss = 2104.8582368324255
Iteration 4000: Loss = 1710.8548348043225
Iteration 5000: Loss = 1342.5955257850537
Iteration 6000: Loss = 1003.7176426782156
Iteration 7000: Loss = 722.7901213683172
Iteration 8000: Loss = 490.81821346400375
Iteration 9000: Loss = 307.6995737498012
Iteration 10000: Loss = 149.87256837417854
Iteration 11000: Loss = 59.755661767573386
Iteration 12000: Loss = 15.790811138123296
Iteration 13000: Loss = 2.2612909430328
Iteration 14000: Loss = 0.1214353478722168
Stopping early at iteration 14820: Loss = 0.08205483382954962
Best loss: 0.08205483382954962 | Parameters: [ 0.15806886 -0.81489577 -0.3388122 ]
Initial loss: 7026.473333949661
Iteration 1000: Loss = 3007.8098679000977
Iteration 2000: Loss = 2450.8073640712114
Iteration 3000: Loss = 1978.5157383721792
Iteration 4000: Loss = 1535.3256044185177
Iteration 5000: Loss = 1156.0954710467784
Iteration 6000: Loss = 822.7754796735825
Iteration 7000: Loss = 539.8938511613553
Iteration 8000: Loss = 326.52641745609
Iteration 9000: Loss = 171.47534191370065
Iteration 10000: Loss = 66.69509147773577
Iteration 11000: Loss = 16.6302132748332
Iteration 12000: Loss = 1.004379911647448
Iteration 13000: Loss = 0.11939827871656625
Stopping early at iteration 13798: Loss = 0.09078032609659925
Best loss: 0.09078032609659925 | Parameters: [ 2.88192538  0.17752569 -1.09193297]
Initial loss: 7026.473333949661
Iteration 1000: Loss = 2922.2103750195256
Iteration 2000: Loss = 2294.645866782543
Iteration 3000: Loss = 1754.0575524704918
Iteration 4000: Loss = 1304.134515079149
Iteration 5000: Loss = 876.5956838773641
Iteration 6000: Loss = 558.4390720616248
Iteration 7000: Loss = 324.788215839698
Iteration 8000: Loss = 152.07322491769904
Iteration 9000: Loss = 46.39368378787305
Iteration 10000: Loss = 4.101262677473436
Iteration 11000: Loss = 0.7677057112442723
Iteration 12000: Loss = 0.09343051296012622
Stopping early at iteration 12527: Loss = 0.08243164170516495
Best loss: 0.08243164170516495 | Parameters: [ 0.92097159 -0.2179795  -0.53379653]
Initial loss: 7026.473333949661
Iteration 1000: Loss = 2849.4361033985374
Iteration 2000: Loss = 2162.2243849699043
Iteration 3000: Loss = 1586.5464359877114
Iteration 4000: Loss = 1074.667452448296
Iteration 5000: Loss = 682.3233349376862
Iteration 6000: Loss = 373.19351312956576
Iteration 7000: Loss = 176.4071483532589
Iteration 8000: Loss = 53.10437095910443
Iteration 9000: Loss = 5.250653076163618
Iteration 10000: Loss = 0.27996075096985507
Iteration 11000: Loss = 0.08311016170736284
Stopping early at iteration 11292: Loss = 0.08311016170736284
Best loss: 0.08311016170736284 | Parameters: [ 0.24598232 -0.00715879 -1.3411204 ]
Initial loss: 7026.473333949661
Iteration 1000: Loss = 2806.362024382885
Iteration 2000: Loss = 2026.2959977327464
Iteration 3000: Loss = 1442.5865331591053
Iteration 4000: Loss = 942.0873107683774
Iteration 5000: Loss = 557.700921306221
Iteration 6000: Loss = 266.6427950651384
Iteration 7000: Loss = 77.15861860200995
Iteration 8000: Loss = 10.032705313591268
Iteration 9000: Loss = 0.11019498018048648
Iteration 10000: Loss = 0.0816347094090967
Stopping early at iteration 10544: Loss = 0.08153554747970454
Best loss: 0.08153554747970454 | Parameters: [0.09824067 0.35190723 0.3886622 ]
Initial loss: 7026.473333949661
Iteration 1000: Loss = 2666.1307185451906
Iteration 2000: Loss = 1840.6762621904752
Iteration 3000: Loss = 1178.1520013710629
Iteration 4000: Loss = 684.8985180523999
Iteration 5000: Loss = 338.7074492442966
Iteration 6000: Loss = 118.95961769966212
Iteration 7000: Loss = 10.620245519645332
Iteration 8000: Loss = 0.3320390848788554
Iteration 9000: Loss = 0.09504509777834645
Stopping early at iteration 9928: Loss = 0.08240226300567094
Best loss: 0.08240226300567094 | Parameters: [0.76273944 0.13945659 0.74164963]
Initial loss: 7026.473333949661
Iteration 1000: Loss = 2567.949417935214
Iteration 2000: Loss = 1722.7985319464353
Iteration 3000: Loss = 1049.1855358554467
Iteration 4000: Loss = 509.9425549284772
Iteration 5000: Loss = 168.1239760038103
Iteration 6000: Loss = 28.511142722475277
Iteration 7000: Loss = 0.10937102411094667
Stopping early at iteration 7964: Loss = 0.09161959092068361
Best loss: 0.09161959092068361 | Parameters: [-0.13876309  2.93953305 -1.30708911]
Initial loss: 7026.473333949661
Iteration 1000: Loss = 2476.3173092348898
Iteration 2000: Loss = 1488.730162633655
Iteration 3000: Loss = 816.2596416082934
Iteration 4000: Loss = 368.93863884788635
Iteration 5000: Loss = 81.28347523810943
Iteration 6000: Loss = 0.44358503298369095
Iteration 7000: Loss = 0.08198271357972013
Stopping early at iteration 7469: Loss = 0.08198271357972013
Best loss: 0.08198271357972013 | Parameters: [-0.06825328 -0.14990199 -0.83939575]
Initial loss: 7026.473333949661
Iteration 1000: Loss = 2406.699335905223
Iteration 2000: Loss = 1389.2495223179465
Iteration 3000: Loss = 688.895229187772
Iteration 4000: Loss = 232.6233263676341
Iteration 5000: Loss = 19.164587882113192
Iteration 6000: Loss = 0.08353789309832968
Stopping early at iteration 6712: Loss = 0.08242348998356064
Best loss: 0.08242348998356064 | Parameters: [0.91983533 0.47731449 0.31394999]
Initial loss: 7026.473333949661
Iteration 1000: Loss = 2307.912371910353
Iteration 2000: Loss = 1222.6695174675592
Iteration 3000: Loss = 460.0835875820733
Iteration 4000: Loss = 89.09899036183387
Iteration 5000: Loss = 0.1734092158059612
Iteration 6000: Loss = 0.08176319815011687
Stopping early at iteration 6057: Loss = 0.08176319815011687
Best loss: 0.08176319815011687 | Parameters: [-0.15776979 -0.67472997  0.17901694]
